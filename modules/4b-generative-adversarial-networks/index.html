<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/nlpwme/libs/katex/katex.min.css"> <link rel=stylesheet  href="/nlpwme/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/nlpwme/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/nlpwme/css/font-awesome.min.css"> <link rel=stylesheet  href="/nlpwme/css/celeste.min.css"> <link rel=icon  type="image/png" sizes=200x200  href="/nlpwme/assets/robot.png"> <link rel=icon  type="image/png" sizes=152x152  href="/nlpwme/assets/robot_smaller_152x152.png"> <link rel=icon  type="image/x-icon" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/x-icon" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <link rel=icon  type="image/png" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/png" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <title>NLPwShiyi | Natural Language Processing with Shiyi</title> <nav id=navbar  class=navigation  role=navigation > <input id=toggle1  type=checkbox  /> <label class=hamburger1  for=toggle1 > <div class=top ></div> <div class=meat ></div> <div class=bottom ></div> </label> <nav class="topnav mx-auto" id=myTopnav > <div class=dropdown > <button class=dropbtn >Comp Ling <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/1b-info-theory">Information Theory</a> <a href="/nlpwme/modules/1c-noisy-channel-model">The Noisy Channel Model</a> <a href="/nlpwme/modules/1d-finite-automata">FSAs and FSTs</a> <a href="/nlpwme/modules/1e-mutual-info">Mutual Information</a> <a href="/nlpwme/modules/1f-cky-algorithm">CKY Algorithm</a> <a href="/nlpwme/modules/1g-viterbi">Viterbi Algorithm</a> <a href="/nlpwme/modules/2b-markov-processes">Markov Processes</a> <a href="/nlpwme/modules/1h-semantics">Logic and Problem Solving</a> <a href="/nlpwme/modules/1j-bayesian">Bayesian Inference</a> </div> </div> <div class=dropdown > <button class=dropbtn  >ML / DL <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/2e-jax">Jacobian Matrices Derivation</a> <a href="/nlpwme/modules/2d-automatic-differentiation">Automatic Differentiation</a> <a href="/nlpwme/modules/2f-loss-functions">Stochastic GD</a> <a href="/nlpwme/modules/2c-word2vec">Word2Vec</a> <a href="/nlpwme/modules/2g-batchnorm">Batchnorm</a> <a href="/nlpwme/modules/2j-perplexity">Perplexity</a> <a href="/nlpwme/modules/2h-dropout">Dropout</a> <a href="/nlpwme/modules/2i-depth">Depth: Pros and Cons</a> <a href="/nlpwme/modules/2k-VAE">Variational Autoencoders</a> <a href="/nlpwme/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a> </div> </div> <a href="/nlpwme/" class=active >Intro </a> <div class=dropdown > <button class=dropbtn  >SOTA <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a> <a href="/nlpwme/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a> <a href="/nlpwme/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a> <a href="/nlpwme/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a> <a href="/nlpwme/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a> </div> </div> <div class=dropdown > <button class=dropbtn  >Hands-on <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/4a-mlp-from-scratch">MLP from Scratch</a> <a href="/nlpwme/modules/4b-generative-adversarial-networks">GAN Example </a> <a href="/nlpwme/modules/4c-vae-mnist">VAE for MNIST</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">BI-LSTM-CRF Seq2Seq</a> <a href="/nlpwme/modules/4e-c4fe-tbip">Measuring Subjectivity with VAE</a> <a href="/nlpwme/modules/4g-etl-job">Serverless ETL Example</a> <a href="/nlpwme/modules/4h-ocr-data-aug">OCR Text Augmentation</a> <a href="/nlpwme/modules/4i-neo4j-gql">Neo4j GQL Example</a> </div> </div> </nav> </nav> <script src="../assets/js/custom.js"></script> <div class=franklin-content ><h1 id=generative_adversarial_networks ><a href="#generative_adversarial_networks" class=header-anchor >Generative Adversarial Networks</a></h1> <p><strong>Table of Contents</strong></p> <div class=franklin-toc ><ol><li><a href="#generative_adversarial_networks__2">Generative Adversarial Networks</a><li><a href="#a_simple_gan">A Simple GAN</a><li><a href="#conditional_gan">Conditional GAN</a><li><a href="#info_gan">Info GAN</a><li><a href="#variational_autoencoders">Variational Autoencoders</a></ol></div> <h2 id=generative_adversarial_networks__2 ><a href="#generative_adversarial_networks__2" class=header-anchor >Generative Adversarial Networks</a></h2> <p>In this section, we play with the GAN described in the lesson on a double moon dataset.</p> <p>Then we implement a Conditional GAN and an InfoGAN.</p> <pre><code class="python hljs"><span class=hljs-comment ># all of these libraries are used for plotting</span>
<span class=hljs-keyword >import</span> numpy <span class=hljs-keyword >as</span> np
<span class=hljs-keyword >import</span> matplotlib.pyplot <span class=hljs-keyword >as</span> plt

<span class=hljs-comment ># Plot the dataset</span>
<span class=hljs-keyword >def</span> <span class="hljs-title function_">plot_data</span>(<span class=hljs-params >ax, X, Y, color = <span class=hljs-string >&#x27;bone&#x27;</span></span>):
    plt.axis(<span class=hljs-string >&#x27;off&#x27;</span>)
    ax.scatter(X[:, <span class=hljs-number >0</span>], X[:, <span class=hljs-number >1</span>], s=<span class=hljs-number >1</span>, c=Y, cmap=color)


<span class=hljs-keyword >from</span> sklearn.datasets <span class=hljs-keyword >import</span> make_moons
X, y = make_moons(n_samples=<span class=hljs-number >2000</span>, noise=<span class=hljs-number >0.05</span>)


n_samples = X.shape[<span class=hljs-number >0</span>]
Y = np.ones(n_samples)
fig, ax = plt.subplots(<span class=hljs-number >1</span>, <span class=hljs-number >1</span>,facecolor=<span class=hljs-string >&#x27;#4B6EA9&#x27;</span>)

plot_data(ax, X, Y)
plt.show()


<span class=hljs-keyword >import</span> torch
device = torch.device(cuda:<span class=hljs-number >0</span> <span class=hljs-keyword >if</span> torch.cuda.is_available() <span class=hljs-keyword >else</span> cpu)

<span class=hljs-built_in >print</span>(<span class=hljs-string >&#x27;Using gpu: %s &#x27;</span> % torch.cuda.is_available())</code></pre> <h2 id=a_simple_gan ><a href="#a_simple_gan" class=header-anchor >A Simple GAN</a></h2> <p>We start with the simple GAN described in the course.</p> <pre><code class="python hljs"><span class=hljs-keyword >import</span> torch.nn <span class=hljs-keyword >as</span> nn

z_dim = <span class=hljs-number >32</span>
hidden_dim = <span class=hljs-number >128</span>

net_G = nn.Sequential(nn.Linear(z_dim,hidden_dim),
                     nn.ReLU(), nn.Linear(hidden_dim, <span class=hljs-number >2</span>))

net_D = nn.Sequential(nn.Linear(<span class=hljs-number >2</span>,hidden_dim),
                     nn.ReLU(),
                     nn.Linear(hidden_dim,<span class=hljs-number >1</span>),
                     nn.Sigmoid())

net_G = net_G.to(device)
net_D = net_D.to(device)</code></pre> <p>Training loop as described here, keeping the losses for the discriminator and the generator.</p> <pre><code class="python hljs">batch_size = <span class=hljs-number >50</span>
lr = <span class=hljs-number >1e-4</span>
nb_epochs = <span class=hljs-number >500</span>

optimizer_G = torch.optim.Adam(net_G.parameters(),lr=lr)
optimizer_D = torch.optim.Adam(net_D.parameters(),lr=lr)

loss_D_epoch = []
loss_G_epoch = []

<span class=hljs-keyword >for</span> e <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(nb_epochs):
    np.random.shuffle(X)
    real_samples = torch.from_numpy(X).<span class=hljs-built_in >type</span>(torch.FloatTensor)
    loss_G = <span class=hljs-number >0</span>
    loss_D = <span class=hljs-number >0</span>
    <span class=hljs-keyword >for</span> t, real_batch <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(real_samples.split(batch_size)):
        <span class=hljs-comment >#improving D</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        fake_batch = net_G(z)
        D_scores_on_real = net_D(real_batch.to(device))
        D_scores_on_fake = net_D(fake_batch)
            
        loss = - torch.mean(torch.log(<span class=hljs-number >1</span>-D_scores_on_fake) 
               + torch.log(D_scores_on_real))
        optimizer_D.zero_grad()
        loss.backward()
        optimizer_D.step()
        loss_D += loss.cpu().data.numpy()
                    
        <span class=hljs-comment ># improving G</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        fake_batch = net_G(z)
        D_scores_on_fake = net_D(fake_batch)
            
        loss = -torch.mean(torch.log(D_scores_on_fake))
        optimizer_G.zero_grad()
        loss.backward()
        optimizer_G.step()
        loss_G += loss.cpu().data.numpy()
           
    loss_D_epoch.append(loss_D)
    loss_G_epoch.append(loss_G)


plt.plot(loss_D_epoch)
plt.plot(loss_G_epoch)


z = torch.empty(n_samples,z_dim).normal_().to(device)
fake_samples = net_G(z)
fake_data = fake_samples.cpu().data.numpy()

fig, ax = plt.subplots(<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, facecolor=<span class=hljs-string >&#x27;#4B6EA9&#x27;</span>)
all_data = np.concatenate((X,fake_data),axis=<span class=hljs-number >0</span>)
Y2 = np.concatenate((np.ones(n_samples),np.zeros(n_samples)))
plot_data(ax, all_data, Y2)
plt.show();

<span class=hljs-comment ># It looks like the GAN is oscillating. Try again with lr=1e-3</span>

<span class=hljs-comment ># We can generate more points</span>

z = torch.empty(<span class=hljs-number >10</span>*n_samples,z_dim).normal_().to(device)
fake_samples = net_G(z)
fake_data = fake_samples.cpu().data.numpy()
fig, ax = plt.subplots(<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, facecolor=<span class=hljs-string >&#x27;#4B6EA9&#x27;</span>)
all_data = np.concatenate((X,fake_data),axis=<span class=hljs-number >0</span>)
Y2 = np.concatenate((np.ones(n_samples),np.zeros(<span class=hljs-number >10</span>*n_samples)))
plot_data(ax, all_data, Y2)
plt.show();</code></pre> <h2 id=conditional_gan ><a href="#conditional_gan" class=header-anchor >Conditional GAN</a></h2> <p>We are now implementing a conditional GAN. We start by separating the two half moons in two clusters as follows:</p> <pre><code class="python hljs">X, Y = make_moons(n_samples=<span class=hljs-number >2000</span>, noise=<span class=hljs-number >0.05</span>)
n_samples = X.shape[<span class=hljs-number >0</span>]
fig, ax = plt.subplots(<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, facecolor=<span class=hljs-string >&#x27;#4B6EA9&#x27;</span>)
plot_data(ax, X, Y)
plt.show()</code></pre> <p>The task is now given a white or black label to generate points in the corresponding cluster.</p> <p>Both the generator and the discriminator take in addition a one hot encoding of the label. The generator will now generate fake points corresponding to the input label. The discriminator, given a pair of sample and label should detect if this is a fake or a real pair.</p> <pre><code class="python hljs">z_dim = <span class=hljs-number >32</span>
hidden_dim = <span class=hljs-number >128</span>
label_dim = <span class=hljs-number >2</span>


<span class=hljs-keyword >class</span> <span class="hljs-title class_">generator</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self,z_dim = z_dim, label_dim=label_dim, 
        hidden_dim =hidden_dim</span>):
        <span class=hljs-built_in >super</span>(generator,<span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.net = nn.Sequential(nn.Linear(z_dim+label_dim,hidden_dim),
                     nn.ReLU(), nn.Linear(hidden_dim, <span class=hljs-number >2</span>))
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, <span class=hljs-built_in >input</span>, label_onehot</span>):
        x = torch.cat([<span class=hljs-built_in >input</span>, label_onehot], <span class=hljs-number >1</span>)
        <span class=hljs-keyword >return</span> <span class="hljs-variable language_">self</span>.net(x)
    
<span class=hljs-keyword >class</span> <span class="hljs-title class_">discriminator</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self,z_dim = z_dim, label_dim=label_dim, 
        hidden_dim =hidden_dim</span>):
        <span class=hljs-built_in >super</span>(discriminator,<span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.net =  nn.Sequential(nn.Linear(<span class=hljs-number >2</span>+label_dim,hidden_dim),
                     nn.ReLU(),
                     nn.Linear(hidden_dim,<span class=hljs-number >1</span>),
                     nn.Sigmoid())
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, <span class=hljs-built_in >input</span>, label_onehot</span>):
        x = torch.cat([<span class=hljs-built_in >input</span>, label_onehot], <span class=hljs-number >1</span>)
        <span class=hljs-keyword >return</span> <span class="hljs-variable language_">self</span>.net(x)
        

net_CG = generator().to(device)
net_CD = discriminator().to(device)</code></pre> <p>You need to code the training loop:</p> <pre><code class="python hljs">batch_size = <span class=hljs-number >50</span>
lr = <span class=hljs-number >1e-3</span>
nb_epochs = <span class=hljs-number >1000</span>

optimizer_CG = torch.optim.Adam(net_CG.parameters(),lr=lr)
optimizer_CD = torch.optim.Adam(net_CD.parameters(),lr=lr)
loss_D_epoch = []
loss_G_epoch = []
<span class=hljs-keyword >for</span> e <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(nb_epochs):
    rperm = np.random.permutation(X.shape[<span class=hljs-number >0</span>]);
    np.take(X,rperm,axis=<span class=hljs-number >0</span>,out=X);
    np.take(Y,rperm,axis=<span class=hljs-number >0</span>,out=Y);
    real_samples = torch.from_numpy(X).<span class=hljs-built_in >type</span>(torch.FloatTensor)
    real_labels = torch.from_numpy(Y).<span class=hljs-built_in >type</span>(torch.LongTensor)
    loss_G = <span class=hljs-number >0</span>
    loss_D = <span class=hljs-number >0</span>
    <span class=hljs-keyword >for</span> real_batch, real_batch_label <span class=hljs-keyword >in</span> <span class=hljs-built_in >zip</span>(real_samples.split(batch_size),
                                            real_labels.split(batch_size)):
            <span class=hljs-comment >#improving D</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here</span>
        <span class=hljs-comment ># hint: https://discuss.pytorch.org/t/</span>
        <span class=hljs-comment ># convert-int-into-one-hot-format/507/4</span>
        <span class=hljs-comment >#</span>
                
        loss = - .mean(torch.log(<span class=hljs-number >1</span>-D_scores_on_fake) 
               + torch.log(D_scores_on_real))
        optimizer_CD.zero_grad()
        loss.backward()
        optimizer_CD.step()
        loss_D += loss.cpu().data.numpy()
            
        <span class=hljs-comment ># improving G</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        
        
        <span class=hljs-comment ># to-do</span>
        
                    
        loss = -torch.mean(torch.log(D_scores_on_fake))
        optimizer_CG.zero_grad()
        loss.backward()
        optimizer_CG.step()
        loss_G += loss.cpu().data.numpy()
                    
    loss_D_epoch.append(loss_D)
    loss_G_epoch.append(loss_G)</code></pre> <pre><code class="python hljs">plt.plot(loss_D_epoch)
plt.plot(loss_G_epoch)</code></pre> <pre><code class="python hljs">z = torch.empty(n_samples,z_dim).normal_().to(device)
label = torch.LongTensor(n_samples,<span class=hljs-number >1</span>).random_() % label_dim
label_onehot = torch.FloatTensor(n_samples, label_dim).zero_()
label_onehot = label_onehot.scatter_(<span class=hljs-number >1</span>, label, <span class=hljs-number >1</span>).to(device)
fake_samples = net_CG(z, label_onehot)
fake_data = fake_samples.cpu().data.numpy()</code></pre> <h2 id=info_gan ><a href="#info_gan" class=header-anchor >Info GAN</a></h2> <p>Here we implement a simplified version of the algorithm presented in the InfoGAN paper.</p> <p>This time, you do not have access to the labels but you know there are two classes. The idea is then to provide as in the conditional GAN a random label to the generator but in opposition to the conditional GAN, the discriminator cannot take as input the label &#40;since they are not provided to us&#41; but instead the discriminator will predict a label and this prediction can be trained on fake samples only&#33;</p> <pre><code class="python hljs"><span class=hljs-keyword >import</span> torch.nn.functional <span class=hljs-keyword >as</span> F

z_dim = <span class=hljs-number >32</span>
hidden_dim = <span class=hljs-number >128</span>
label_dim = <span class=hljs-number >2</span>


<span class=hljs-keyword >class</span> <span class="hljs-title class_">Igenerator</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self,z_dim = z_dim, label_dim=label_dim, 
        hidden_dim =hidden_dim</span>):
        <span class=hljs-built_in >super</span>(Igenerator,<span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.net = nn.Sequential(nn.Linear(z_dim+label_dim,hidden_dim),
                     nn.ReLU(), nn.Linear(hidden_dim, <span class=hljs-number >2</span>))
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, <span class=hljs-built_in >input</span>, label_onehot</span>):
        x = torch.cat([<span class=hljs-built_in >input</span>, label_onehot], <span class=hljs-number >1</span>)
        <span class=hljs-keyword >return</span> <span class="hljs-variable language_">self</span>.net(x)
    
<span class=hljs-keyword >class</span> <span class="hljs-title class_">Idiscriminator</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self,z_dim = z_dim, label_dim=label_dim, 
        hidden_dim =hidden_dim</span>):
        <span class=hljs-built_in >super</span>(Idiscriminator,<span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class=hljs-number >2</span>,hidden_dim)
        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(hidden_dim,<span class=hljs-number >1</span>)
        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(hidden_dim,<span class=hljs-number >1</span>)
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, <span class=hljs-built_in >input</span></span>):
        x = F.relu(<span class="hljs-variable language_">self</span>.fc1(<span class=hljs-built_in >input</span>))
        output = torch.sigmoid(<span class="hljs-variable language_">self</span>.fc2(x))
        est_label = torch.sigmoid(<span class="hljs-variable language_">self</span>.fc3(x)) 
        <span class=hljs-keyword >return</span> output, est_label
        

net_IG = Igenerator().to(device)
net_ID = Idiscriminator().to(device)</code></pre> <p><strong>Here, we add loss_fn which is the BCELoss to be used for the binary classification task of the discriminator on the fake samples.</strong></p> <pre><code class="python hljs">batch_size = <span class=hljs-number >50</span>
lr = <span class=hljs-number >1e-3</span>
nb_epochs = <span class=hljs-number >1000</span>
loss_fn = nn.BCELoss()

optimizer_IG = torch.optim.Adam(net_IG.parameters(),lr=lr)
optimizer_ID = torch.optim.Adam(net_ID.parameters(),lr=lr)
loss_D_epoch = []
loss_G_epoch = []
<span class=hljs-keyword >for</span> e <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(nb_epochs):
    
    rperm = np.random.permutation(X.shape[<span class=hljs-number >0</span>]);
    np.take(X,rperm,axis=<span class=hljs-number >0</span>,out=X);
    <span class=hljs-comment >#np.take(Y,rperm,axis=0,out=Y);</span>
    real_samples = torch.from_numpy(X).<span class=hljs-built_in >type</span>(torch.FloatTensor)
    <span class=hljs-comment >#real_labels = torch.from_numpy(Y).type(torch.LongTensor)</span>
    loss_G = <span class=hljs-number >0</span>
    loss_D = <span class=hljs-number >0</span>
    <span class=hljs-keyword >for</span> real_batch <span class=hljs-keyword >in</span> real_samples.split(batch_size):
       
        <span class=hljs-comment ># improving D</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here</span>
        <span class=hljs-comment >#</span>
        
            
            <span class=hljs-comment ># improving G</span>
        z = torch.empty(batch_size,z_dim).normal_().to(device)
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here</span>
        <span class=hljs-comment >#</span>
               
            
    loss_D_epoch.append(loss_D)
    loss_G_epoch.append(loss_G)


plt.plot(loss_D_epoch)
plt.plot(loss_G_epoch)


z = torch.empty(n_samples,z_dim).normal_().to(device)
label = torch.LongTensor(n_samples,<span class=hljs-number >1</span>).random_() % label_dim
label_onehot = torch.FloatTensor(n_samples, label_dim).zero_()
label_onehot = label_onehot.scatter_(<span class=hljs-number >1</span>, label, <span class=hljs-number >1</span>).to(device)
fake_samples = net_IG(z, label_onehot)
fake_data = fake_samples.cpu().data.numpy()</code></pre> <h2 id=variational_autoencoders ><a href="#variational_autoencoders" class=header-anchor >Variational Autoencoders</a></h2> <p>Consider a latent variable model with a data variable <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mi mathvariant=script >X</mi></mrow><annotation encoding="application/x-tex">x\in \mathcal{X}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span> and a latent variable <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>∈</mo><mi mathvariant=script >Z</mi></mrow><annotation encoding="application/x-tex">z\in \mathcal{Z}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo separator=true >,</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(z,x) = p(z)p_\theta(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>. Given the data <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator=true >,</mo><mo>…</mo><mo separator=true >,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1,\dots, x_n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner >…</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we want to train the model by maximizing the marginal log-likelihood:</p> <div class=nonumber ><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.16em  columnalign="right center left" columnspacing=1em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=false ><mrow><mi mathvariant=script >L</mi><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mo>∫</mo><mi mathvariant=script >Z</mi></msub><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mi>d</mi><mi>z</mi><mo fence=true >]</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{rcl} \mathcal{L} = \mathbf{E}_{p_d(x)}\left[\log p_\theta(x)\right]=\mathbf{E}_{p_d(x)}\left[\log \int_{\mathcal{Z}}p_{\theta}(x|z)p(z)dz\right] \end{array}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.21em;vertical-align:-0.355em;"></span><span class=mord ><span class=mtable ><span class=arraycolsep  style="width:0.5em;"></span><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.855em;"><span style="top:-3.005em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathcal">L</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop ><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0006em;">∫</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1225em;"><span style="top:-2.3442em;margin-left:-0.1945em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.07944em;">Z</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3558em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.355em;"><span></span></span></span></span></span><span class=arraycolsep  style="width:0.5em;"></span></span></span></span></span></span></span></div> <p>where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">p_d</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> denotes the empirical distribution of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>δ</mi><msub><mi>x</mi><mi>i</mi></msub></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_d(x) =\frac{1}{n}\sum_{i=1}^n \delta_{x_i}(x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1.1901em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8451em;"><span style="top:-2.655em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2997em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2501em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span>.</p> <p>To avoid the &#40;often&#41; difficult computation of the integral above, the idea behind variational methods is to instead maximize a lower bound to the log-likelihood:</p> <div class=nonumber ><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.16em  columnalign="right center left" columnspacing=1em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=false ><mrow><mi mathvariant=script >L</mi><mo>≥</mo><mi>L</mi><mo stretchy=false >(</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo separator=true >,</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mo stretchy=false >)</mo><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><msub><mi mathvariant=bold >E</mi><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow><mo>−</mo><mrow><mi mathvariant=normal >K</mi><mi mathvariant=normal >L</mi></mrow><mrow><mo fence=true >(</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >)</mo></mrow><mo fence=true >]</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{rcl} \mathcal{L} \geq L(p_\theta(x|z),q(z|x)) =\mathbf{E}_{p_d(x)}\left[\mathbf{E}_{q(z|x)}\left[\log p_\theta(x|z)\right]-\mathrm{KL}\left( q(z|x)||p(z)\right)\right] \end{array}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.21em;vertical-align:-0.355em;"></span><span class=mord ><span class=mtable ><span class=arraycolsep  style="width:0.5em;"></span><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.855em;"><span style="top:-3.005em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathcal">L</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >≥</span><span class=mspace  style="margin-right:0.2778em;"></span><span class="mord mathnormal">L</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >))</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mord ><span class="mord mathrm">KL</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mord >∣∣</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.355em;"><span></span></span></span></span></span><span class=arraycolsep  style="width:0.5em;"></span></span></span></span></span></span></span></div> <p>Any choice of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> gives a valid lower bound. Variational autoencoders replace the variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> by an inference network <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_{\phi}(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> that is trained together with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span> to jointly maximize <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy=false >(</mo><msub><mi>p</mi><mi>θ</mi></msub><mo separator=true >,</mo><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">L(p_\theta,q_\phi)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">L</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span>.</p> <p>The variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_{\phi}(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> is also called the <strong>encoder</strong> and the generative model <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>, the <strong>decoder</strong> or generator.</p> <p>The first term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant=bold >E</mi><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_{q(z|x)}\left[\log p_\theta(x|z)\right]</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.1052em;vertical-align:-0.3552em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span> is the negative reconstruction error. Indeed under a gaussian assumption i.e. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo>=</mo><mi mathvariant=script >N</mi><mo stretchy=false >(</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo separator=true >,</mo><mi>I</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z) = \mathcal{N}(\mu_{\theta}(z), I)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">μ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mclose >)</span></span></span></span> the term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\log p_\theta(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span> reduces to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∝</mo><mi mathvariant=normal >∥</mi><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><msup><mi mathvariant=normal >∥</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\propto \|x-\mu_\theta(z)\|^2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.4306em;"></span><span class=mrel >∝</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >∥</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1.0641em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">μ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mord ><span class=mord >∥</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>, which is often used in practice. The term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant=normal >K</mi><mi mathvariant=normal >L</mi></mrow><mrow><mo fence=true >(</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{KL}\left( q(z|x)||p(z)\right)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathrm">KL</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mord >∣∣</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> can be seen as a regularization term, where the variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_\phi(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> should be matched to the prior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo>=</mo><mi mathvariant=script >N</mi><mo stretchy=false >(</mo><mn>0</mn><mo separator=true >,</mo><mi>I</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(z)= \mathcal{N}(0, I)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class=mopen >(</span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mclose >)</span></span></span></span>.</p> <p>Variational Autoencoders were introduced by <a href="https://arxiv.org/abs/1312.6114">Kingma and Welling &#40;2013&#41;</a>, see also <a href="https://arxiv.org/abs/1606.05908">&#40;Doersch, 2016&#41;</a> for a tutorial.</p> <p>There are various examples of VAE in PyTorch available <a href="https://github.com/pytorch/examples/tree/master/vae">here</a> or <a href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65">here</a>. The code below is taken from this last source.</p> <div class=page-foot > <div class=copyright > <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a> ©️ Last modified: December 04, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/nlpwme/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>