<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/nlpwme/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/nlpwme/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/nlpwme/css/font-awesome.min.css"> <link rel=stylesheet  href="/nlpwme/css/celeste.min.css"> <link rel=icon  type="image/png" sizes=200x200  href="/nlpwme/assets/robot.png"> <link rel=icon  type="image/png" sizes=152x152  href="/nlpwme/assets/robot_smaller_152x152.png"> <link rel=icon  type="image/x-icon" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/x-icon" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <link rel=icon  type="image/png" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/png" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <title>NLPwShiyi | Natural Language Processing with Shiyi</title> <nav id=navbar  class=navigation  role=navigation > <input id=toggle1  type=checkbox  /> <label class=hamburger1  for=toggle1 > <div class=top ></div> <div class=meat ></div> <div class=bottom ></div> </label> <nav class="topnav mx-auto" id=myTopnav > <div class=dropdown > <button class=dropbtn >Comp Ling <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/1b-info-theory">Information Theory</a> <a href="/nlpwme/modules/1c-noisy-channel-model">The Noisy Channel Model</a> <a href="/nlpwme/modules/1d-finite-automata">FSAs and FSTs</a> <a href="/nlpwme/modules/1e-mutual-info">Mutual Information</a> <a href="/nlpwme/modules/1f-cky-algorithm">CKY Algorithm</a> <a href="/nlpwme/modules/1g-viterbi">Viterbi Algorithm</a> <a href="/nlpwme/modules/2b-markov-processes">Markov Processes</a> <a href="/nlpwme/modules/1h-semantics">Logic and Problem Solving</a> <a href="/nlpwme/modules/1j-bayesian">Bayesian Inference</a> </div> </div> <div class=dropdown > <button class=dropbtn  >ML / DL <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/2e-jax">Jacobian Matrices Derivation</a> <a href="/nlpwme/modules/2d-automatic-differentiation">Automatic Differentiation</a> <a href="/nlpwme/modules/2f-loss-functions">Stochastic GD</a> <a href="/nlpwme/modules/2c-word2vec">Word2Vec</a> <a href="/nlpwme/modules/2g-batchnorm">Batchnorm</a> <a href="/nlpwme/modules/2j-perplexity">Perplexity</a> <a href="/nlpwme/modules/2h-dropout">Dropout</a> <a href="/nlpwme/modules/2i-depth">Depth: Pros and Cons</a> <a href="/nlpwme/modules/2k-VAE">Variational Autoencoders</a> <a href="/nlpwme/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a> </div> </div> <a href="/nlpwme/" class=active >Intro </a> <div class=dropdown > <button class=dropbtn  >SOTA <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a> <a href="/nlpwme/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a> <a href="/nlpwme/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a> <a href="/nlpwme/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a> <a href="/nlpwme/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a> </div> </div> <div class=dropdown > <button class=dropbtn  >Hands-on <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/4a-mlp-from-scratch">MLP from Scratch</a> <a href="/nlpwme/modules/4b-generative-adversarial-networks">GAN Example </a> <a href="/nlpwme/modules/4c-vae-mnist">VAE for MNIST</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">BI-LSTM-CRF Seq2Seq</a> <a href="/nlpwme/modules/4e-c4fe-tbip">Measuring Subjectivity with VAE</a> <a href="/nlpwme/modules/4g-etl-job">Serverless ETL Example</a> <a href="/nlpwme/modules/4h-ocr-data-aug">OCR Text Augmentation</a> <a href="/nlpwme/modules/4i-neo4j-gql">Neo4j GQL Example</a> </div> </div> </nav> </nav> <script src="../assets/js/custom.js"></script> <div class=franklin-content ><h1 id=what_is_data_augmentation ><a href="#what_is_data_augmentation" class=header-anchor >What Is Data Augmentation? </a></h1> <p>Data augmentation is a technique commonly used in machine learning and deep learning to artificially increase the size of a dataset by creating modified versions of existing data samples. The goal of data augmentation is to improve the generalization and robustness of a machine learning model by exposing it to a wider variety of training examples, thus reducing overfitting.</p> <p>Data augmentation techniques involve applying a series of transformations or modifications to the original data samples while preserving their underlying labels or characteristics. These transformations can include:</p> <ol> <li><p><strong>Geometric transformations</strong>: Such as rotation, scaling, translation, flipping, and cropping. These transformations can help the model become invariant to changes in orientation, position, and scale.</p> <li><p><strong>Color and pixel-level transformations</strong>: Such as brightness adjustment, contrast adjustment, hue and saturation changes, and adding random noise. These modifications can help the model become more robust to variations in lighting conditions and color distributions.</p> <li><p><strong>Spatial transformations</strong>: Such as elastic deformations, perspective transformations, and random occlusions. These transformations mimic real-world distortions and variations in input data.</p> </ol> <p>Data augmentation is particularly useful when working with limited or imbalanced datasets, as it allows for the generation of additional training examples without the need for collecting new data. By exposing the model to a more diverse range of examples during training, data augmentation can help improve its ability to generalize to unseen data and enhance its overall performance.</p> <h1 id=how_is_it_applied_in_nlp_tasks ><a href="#how_is_it_applied_in_nlp_tasks" class=header-anchor >How is it applied in NLP tasks? </a></h1> <p>Natural Language Processing &#40;NLP&#41; techniques applied to electronic health records &#40;EHRs&#41; play a significant role in extracting valuable insights from the vast amount of textual data contained within these records. Optical Character Recognition &#40;OCR&#41; is often used to convert scanned or handwritten documents into machine-readable text, enabling further analysis using NLP techniques.</p> <p>When dealing with OCR and NLP tasks in the healthcare domain, data augmentation techniques can be beneficial in several ways:</p> <ol> <li><p><strong>Increasing Training Data</strong>: Healthcare datasets are often limited in size due to privacy concerns and data access restrictions. Data augmentation techniques can artificially increase the size of the training dataset by generating variations of existing text data. For example, generating synonyms or paraphrases of medical terms or sentences can create additional training examples without the need for collecting more data.</p> <li><p><strong>Enhancing Model Robustness</strong>: OCR systems may encounter various challenges when processing medical documents, such as low-quality scans, handwritten notes, or inconsistent formatting. Data augmentation techniques can simulate these real-world variations by introducing noise or distortions to the text data. Models trained on augmented data are more likely to generalize well to unseen or noisy inputs, improving overall performance.</p> <li><p><strong>Addressing Data Imbalance</strong>: EHRs often contain imbalanced distributions of clinical concepts or conditions, with certain rare conditions having fewer examples compared to more common ones. Data augmentation can be used to create synthetic examples of underrepresented classes, helping to balance the dataset and prevent bias in model training.</p> <li><p><strong>Privacy Preservation</strong>: In healthcare, privacy regulations such as HIPAA &#40;Health Insurance Portability and Accountability Act&#41; restrict the sharing of patient data. Data augmentation techniques can generate synthetic data that preserves the statistical properties of the original data while mitigating privacy risks. Differential privacy methods, for example, add noise to the data to protect individual privacy while maintaining overall data utility.</p> <li><p><strong>Domain-Specific Augmentation</strong>: Healthcare data often contains specialized terminology and domain-specific language. Data augmentation techniques tailored to the healthcare domain, such as medical synonym replacement or generation of clinically plausible variations, can improve the relevance and effectiveness of the augmented data for training NLP models on healthcare tasks.</p> </ol> <p>Overall, the combination of OCR with NLP and data augmentation techniques holds great promise for unlocking valuable insights from electronic health records, improving clinical decision-making, healthcare delivery, and medical research. However, it&#39;s crucial to ensure that augmented data retains the integrity and fidelity of the original information, especially in sensitive healthcare applications.</p> <h1 id=a_simple_textual_data_augmentation_with_nltk_toolkit ><a href="#a_simple_textual_data_augmentation_with_nltk_toolkit" class=header-anchor >A simple textual data augmentation with NLTK toolkit</a></h1> <pre><code class="python hljs"><span class=hljs-keyword >import</span> nltk
<span class=hljs-keyword >from</span> nltk.corpus <span class=hljs-keyword >import</span> wordnet
<span class=hljs-keyword >import</span> random

<span class=hljs-keyword >def</span> <span class="hljs-title function_">augment_text</span>(<span class=hljs-params >sentence, num_synonyms=<span class=hljs-number >1</span></span>):
    <span class=hljs-comment ># Tokenize the sentence into words</span>
    words = nltk.word_tokenize(sentence)
    augmented_sentences = []

    <span class=hljs-keyword >for</span> _ <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(num_synonyms):
        <span class=hljs-comment ># Iterate through each word in the sentence</span>
        <span class=hljs-keyword >for</span> i, word <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(words):
            <span class=hljs-comment ># Get synonyms for the word using WordNet</span>
            synonyms = []
            <span class=hljs-keyword >for</span> syn <span class=hljs-keyword >in</span> wordnet.synsets(word):
                <span class=hljs-keyword >for</span> lemma <span class=hljs-keyword >in</span> syn.lemmas():
                    synonyms.append(lemma.name())

            <span class=hljs-comment ># Replace the word with a random synonym if available</span>
            <span class=hljs-keyword >if</span> synonyms:
                random_synonym = random.choice(synonyms)
                words[i] = random_synonym

        <span class=hljs-comment ># Join the words back into a sentence</span>
        augmented_sentence = <span class=hljs-string >&#x27; &#x27;</span>.join(words)
        augmented_sentences.append(augmented_sentence)

    <span class=hljs-keyword >return</span> augmented_sentences

<span class=hljs-comment ># Example usage</span>
original_sentence = <span class=hljs-string >&quot;The patient presented with symptoms of influenza.&quot;</span>
augmented_sentences = augment_text(original_sentence, num_synonyms=<span class=hljs-number >3</span>)

<span class=hljs-built_in >print</span>(<span class=hljs-string >&quot;Original Sentence:&quot;</span>)
<span class=hljs-built_in >print</span>(original_sentence)
<span class=hljs-built_in >print</span>(<span class=hljs-string >&quot;\nAugmented Sentences:&quot;</span>)
<span class=hljs-keyword >for</span> idx, sentence <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(augmented_sentences):
    <span class=hljs-built_in >print</span>(<span class=hljs-string >f&quot;<span class=hljs-subst >{idx + <span class=hljs-number >1</span>}</span>. <span class=hljs-subst >{sentence}</span>&quot;</span>)</code></pre> <h1 id=a_more_in-depth_example_of_data_augmentation_of_ocr_hand_writing_or_electronic_health_records ><a href="#a_more_in-depth_example_of_data_augmentation_of_ocr_hand_writing_or_electronic_health_records" class=header-anchor >A More In-depth Example of Data Augmentation of OCR Hand Writing or Electronic Health Records </a></h1> <p>In this example, we&#39;ll simulate OCR text data extracted from health records and perform data augmentation by adding noise to the text.</p> <pre><code class="python hljs"><span class=hljs-keyword >import</span> numpy <span class=hljs-keyword >as</span> np

<span class=hljs-keyword >def</span> <span class="hljs-title function_">simulate_ocr_text_data</span>(<span class=hljs-params >num_samples, max_length=<span class=hljs-number >100</span></span>):
    <span class=hljs-comment ># Simulate OCR text data as numpy arrays</span>
    ocr_data = []
    <span class=hljs-keyword >for</span> _ <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(num_samples):
        <span class=hljs-comment ># Generate random text data with varying lengths</span>
        text_length = np.random.randint(<span class=hljs-number >1</span>, max_length)
        text = <span class=hljs-string >&#x27;&#x27;</span>.join(np.random.choice(<span class=hljs-built_in >list</span>(<span class=hljs-string >&#x27;abcdefghijklmnopqrstuvwxyz &#x27;</span>), size=text_length))
        ocr_data.append(text)

    <span class=hljs-keyword >return</span> ocr_data

<span class=hljs-keyword >def</span> <span class="hljs-title function_">add_noise_to_text</span>(<span class=hljs-params >text, noise_level=<span class=hljs-number >0.1</span></span>):
    <span class=hljs-comment ># Add random noise to the text</span>
    noisy_text = <span class=hljs-string >&#x27;&#x27;</span>
    <span class=hljs-keyword >for</span> char <span class=hljs-keyword >in</span> text:
        <span class=hljs-keyword >if</span> np.random.random() &lt; noise_level:
            <span class=hljs-comment ># Add random noise with 10% probability</span>
            noisy_text += np.random.choice(<span class=hljs-built_in >list</span>(<span class=hljs-string >&#x27;abcdefghijklmnopqrstuvwxyz &#x27;</span>))
        <span class=hljs-keyword >else</span>:
            noisy_text += char
    <span class=hljs-keyword >return</span> noisy_text

<span class=hljs-comment ># Simulate OCR text data</span>
num_samples = <span class=hljs-number >5</span>
ocr_data = simulate_ocr_text_data(num_samples)

<span class=hljs-comment ># Add noise to the OCR text data for augmentation</span>
noisy_ocr_data = [add_noise_to_text(text) <span class=hljs-keyword >for</span> text <span class=hljs-keyword >in</span> ocr_data]

<span class=hljs-comment ># Print original and augmented OCR text data</span>
<span class=hljs-built_in >print</span>(<span class=hljs-string >&quot;Original OCR Text Data:&quot;</span>)
<span class=hljs-keyword >for</span> idx, text <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(ocr_data):
    <span class=hljs-built_in >print</span>(<span class=hljs-string >f&quot;<span class=hljs-subst >{idx + <span class=hljs-number >1</span>}</span>. <span class=hljs-subst >{text}</span>&quot;</span>)

<span class=hljs-built_in >print</span>(<span class=hljs-string >&quot;\nAugmented OCR Text Data:&quot;</span>)
<span class=hljs-keyword >for</span> idx, noisy_text <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(noisy_ocr_data):
    <span class=hljs-built_in >print</span>(<span class=hljs-string >f&quot;<span class=hljs-subst >{idx + <span class=hljs-number >1</span>}</span>. <span class=hljs-subst >{noisy_text}</span>&quot;</span>)</code></pre> <p>In this code:</p> <ul> <li><p><code>simulate_ocr_text_data</code> function generates imaginary OCR text data represented as numpy arrays, where each array contains a random sequence of lowercase letters and spaces.</p> <li><p><code>add_noise_to_text</code> function adds random noise to the input text with a specified noise level. Here, we randomly replace characters with other lowercase letters or spaces with a probability of 10&#37;.</p> <li><p>We simulate OCR text data for a specified number of samples &#40;<code>num_samples</code>&#41; and add noise to each sample to create augmented data.</p> <li><p>Finally, we print both the original and augmented OCR text data.</p> </ul> <p>This example demonstrates a simple way to perform data augmentation on OCR text data represented as numpy arrays by adding noise to the text.</p> <p>In summary, data augmentation enhances datasets by generating modified versions of existing samples, aiding machine learning models&#39; performance. It involves techniques like geometric transformations, color adjustments, and synthetic data generation. Augmented data increases diversity, mitigates overfitting, and improves model robustness. In OCR for healthcare, augmentation ensures privacy preservation, addresses data imbalance, and enhances model adaptability to varied text inputs. For instance, adding noise to OCR-extracted health records improves model generalization. Overall, data augmentation is vital for training robust models, especially in scenarios with limited or imbalanced data, like electronic health records analysis.</p> <div class=page-foot > <div class=copyright > <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a> ©️ Last modified: December 04, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/nlpwme/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>