<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/nlpwme/libs/katex/katex.min.css"> <link rel=stylesheet  href="/nlpwme/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/nlpwme/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/nlpwme/css/font-awesome.min.css"> <link rel=stylesheet  href="/nlpwme/css/celeste.min.css"> <link rel=icon  type="image/png" sizes=200x200  href="/nlpwme/assets/robot.png"> <link rel=icon  type="image/png" sizes=152x152  href="/nlpwme/assets/robot_smaller_152x152.png"> <link rel=icon  type="image/x-icon" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/x-icon" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <link rel=icon  type="image/png" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/png" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <title>NLPwShiyi | Natural Language Processing with Shiyi</title> <nav id=navbar  class=navigation  role=navigation > <input id=toggle1  type=checkbox  /> <label class=hamburger1  for=toggle1 > <div class=top ></div> <div class=meat ></div> <div class=bottom ></div> </label> <nav class="topnav mx-auto" id=myTopnav > <div class=dropdown > <button class=dropbtn >Comp Ling <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/1b-info-theory">Information Theory</a> <a href="/nlpwme/modules/1c-noisy-channel-model">The Noisy Channel Model</a> <a href="/nlpwme/modules/1d-finite-automata">FSAs and FSTs</a> <a href="/nlpwme/modules/1e-mutual-info">Mutual Information</a> <a href="/nlpwme/modules/1f-cky-algorithm">CKY Algorithm</a> <a href="/nlpwme/modules/1g-viterbi">Viterbi Algorithm</a> <a href="/nlpwme/modules/2b-markov-processes">Markov Processes</a> <a href="/nlpwme/modules/1h-semantics">Logic and Problem Solving</a> <a href="/nlpwme/modules/1j-bayesian">Bayesian Inference</a> </div> </div> <div class=dropdown > <button class=dropbtn  >ML / DL <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/2e-jax">Jacobian Matrices Derivation</a> <a href="/nlpwme/modules/2d-automatic-differentiation">Automatic Differentiation</a> <a href="/nlpwme/modules/2f-loss-functions">Stochastic GD</a> <a href="/nlpwme/modules/2c-word2vec">Word2Vec</a> <a href="/nlpwme/modules/2g-batchnorm">Batchnorm</a> <a href="/nlpwme/modules/2j-perplexity">Perplexity</a> <a href="/nlpwme/modules/2h-dropout">Dropout</a> <a href="/nlpwme/modules/2i-depth">Depth: Pros and Cons</a> <a href="/nlpwme/modules/2k-VAE">Variational Autoencoders</a> <a href="/nlpwme/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a> </div> </div> <a href="/nlpwme/" class=active >Intro </a> <div class=dropdown > <button class=dropbtn  >SOTA <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a> <a href="/nlpwme/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a> <a href="/nlpwme/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a> <a href="/nlpwme/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a> <a href="/nlpwme/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a> </div> </div> <div class=dropdown > <button class=dropbtn  >Hands-on <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/4a-mlp-from-scratch">MLP from Scratch</a> <a href="/nlpwme/modules/4b-generative-adversarial-networks">GAN Example </a> <a href="/nlpwme/modules/4c-vae-mnist">VAE for MNIST</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">BI-LSTM-CRF Seq2Seq</a> <a href="/nlpwme/modules/4e-c4fe-tbip">Measuring Subjectivity with VAE</a> <a href="/nlpwme/modules/4g-etl-job">Serverless ETL Example</a> <a href="/nlpwme/modules/4h-ocr-data-aug">OCR Text Augmentation</a> <a href="/nlpwme/modules/4i-neo4j-gql">Neo4j GQL Example</a> </div> </div> </nav> </nav> <script src="../assets/js/custom.js"></script> <div class=franklin-content ><h2 id=making_dynamic_decisions_with_sequence_to_sequence_language_processing_tasks ><a href="#making_dynamic_decisions_with_sequence_to_sequence_language_processing_tasks" class=header-anchor >Making Dynamic Decisions with Sequence to Sequence Language Processing Tasks</a></h2> <div class=franklin-toc ><ol><li><a href="#making_dynamic_decisions_with_sequence_to_sequence_language_processing_tasks">Making Dynamic Decisions with Sequence to Sequence Language Processing Tasks</a></ol></div> <p>We will examine a comprehensive, intricate example of a Bi-LSTM Conditional Random Field for named-entity recognition in this section.</p> <p>For part-of-speech tagging, the LSTM tagger mentioned above is usually adequate; but, for good performance on NER, a sequence model such as the CRF is truly necessary.</p> <p>Knowledge of CRFs is presumed. Despite the ominous moniker, this model is really a CRF with features provided by an LSTM.</p> <p>However, compared to the previous models in this tutorial, this one is far more complex and intricate. It&#39;s okay if you choose not to participate. Try the following to see whether you&#39;re ready:</p> <ul> <li><p>At step <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> for tag <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>, write the recurrence for the viterbi variable.</p> <li><p>To compute the forward variables, alter the recurrence above.</p> <li><p>To calculate the forward variables in log-space, modify the aforementioned recurrence one more &#40;hint: log-sum-exp&#41;.</p> </ul> <p>The code below should make sense to you if you can accomplish those three tasks. Remember that a conditional probability is computed by the CRF. Let x be the word input sequence and y be the tag sequence. </p> <p>The graphic is composed of mathematical formulas and explanations pertaining to a Bi-LSTM neural network and Conditional Random Field &#40;CRF&#41; model used for sequence tagging tasks. The LaTeX formulae are as follows:</p> <ol> <li><p>The conditional probability of a tag sequence <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> given an input sequence <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> is computed as:</p> </ol> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy=false >(</mo><mtext>Score</mtext><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><mi>y</mi><mo stretchy=false >)</mo><mo stretchy=false >)</mo></mrow><mrow><munder><mo>∑</mo><msup><mi>y</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup></munder><mi>exp</mi><mo>⁡</mo><mo stretchy=false >(</mo><mtext>Score</mtext><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><msup><mi>y</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >)</mo><mo stretchy=false >)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex"> P(y|x) = \frac{\exp(\text{Score}(x, y))}{\sum_{y&#x27;} \exp(\text{Score}(x, y&#x27;))} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:2.5488em;vertical-align:-1.1218em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1783em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.4358em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >exp</span><span class=mopen >(</span><span class="mord text"><span class=mord >Score</span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.6779em;"><span style="top:-2.989em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mclose >))</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mop >exp</span><span class=mopen >(</span><span class="mord text"><span class=mord >Score</span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >))</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> <ol start=2 > <li><p>The score of a sequence is the sum of log potentials <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ψ</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\psi_i(x, y)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span>:</p> </ol> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mtext>Score</mtext><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><mi>y</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>log</mi><mo>⁡</mo><msub><mi>ψ</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> \text{Score}(x, y) = \sum_{i} \log \psi_i(x, y) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >Score</span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span></span> <ol start=3 > <li><p>The score is further detailed for a Bi-LSTM CRF model, considering emission and transition potentials:</p> </ol> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mtext>Score</mtext><mo stretchy=false >(</mo><mi>x</mi><mo separator=true >,</mo><mi>y</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>log</mi><mo>⁡</mo><msub><mi>ψ</mi><mtext>EMIT</mtext></msub><mo stretchy=false >(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>→</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=false >)</mo><mo>+</mo><mi>log</mi><mo>⁡</mo><msub><mi>ψ</mi><mtext>TRANS</mtext></msub><mo stretchy=false >(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>→</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> \text{Score}(x, y) = \sum_{i} \log \psi_{\text{EMIT}}(y_i \rightarrow x_i) + \log \psi_{\text{TRANS}}(y_{i-1} \rightarrow y_i) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >Score</span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">EMIT</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >→</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">TRANS</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2083em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >→</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span></span> <ol start=4 > <li><p>The score is then expressed in terms of the hidden state <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8444em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">h</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the Bi-LSTM and the transition scores <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><msub><mi>y</mi><mi>i</mi></msub><mo separator=true >,</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msub></mrow><annotation encoding="application/x-tex">P_{y_i,y_{i-1}}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.9751em;vertical-align:-0.2918em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2025em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2918em;"><span></span></span></span></span></span></span></span></span></span>:</p> </ol> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=false >[</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=false >]</mo><mo>+</mo><msub><mi>P</mi><mrow><msub><mi>y</mi><mi>i</mi></msub><mo separator=true >,</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msub></mrow><annotation encoding="application/x-tex">= \sum_{i} h_i[y_i] + P_{y_i,y_{i-1}}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.3669em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">h</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >[</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >]</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.9751em;vertical-align:-0.2918em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2025em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2918em;"><span></span></span></span></span></span></span></span></span></span></span> <p>Additionally, the text states that in order to make the partition function tractable, the potentials must only consider local features. The transition scores are kept in a matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>, where the score of transitioning from tag <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> to tag <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> is represented by the symbol <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>j</mi><mo separator=true >,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{j,k}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.9694em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>.</p> <p>The following example uses the viterbi algorithm for decoding and the forward method in log space to calculate the partition function. The gradients will be computed automatically for us via backpropagation. Nothing needs to be done by hand.</p> <p>There is inefficiency in the implementation. If you comprehend what&#39;s happening, you&#39;ll undoubtedly notice quite soon that the forward algorithm&#39;s iteration over the next tag may potentially be completed in a single large operation.</p> <pre><code class="python hljs"><span class=hljs-keyword >import</span> torch
<span class=hljs-keyword >import</span> torch.autograd <span class=hljs-keyword >as</span> autograd
<span class=hljs-keyword >import</span> torch.nn <span class=hljs-keyword >as</span> nn
<span class=hljs-keyword >import</span> torch.optim <span class=hljs-keyword >as</span> optim

torch.manual_seed(<span class=hljs-number >1</span>)</code></pre> <pre><code class="python hljs"><span class=hljs-keyword >def</span> <span class="hljs-title function_">argmax</span>(<span class=hljs-params >vec</span>):
    <span class=hljs-comment ># return the argmax as a python int</span>
    _, idx = torch.<span class=hljs-built_in >max</span>(vec, <span class=hljs-number >1</span>)
    <span class=hljs-keyword >return</span> idx.item()


<span class=hljs-keyword >def</span> <span class="hljs-title function_">prepare_sequence</span>(<span class=hljs-params >seq, to_ix</span>):
    idxs = [to_ix[w] <span class=hljs-keyword >for</span> w <span class=hljs-keyword >in</span> seq]
    <span class=hljs-keyword >return</span> torch.tensor(idxs, dtype=torch.long)


<span class=hljs-comment ># Compute log sum exp in a numerically stable way for the forward algorithm</span>
<span class=hljs-keyword >def</span> <span class="hljs-title function_">log_sum_exp</span>(<span class=hljs-params >vec</span>):
    max_score = vec[<span class=hljs-number >0</span>, argmax(vec)]
    max_score_broadcast = max_score.view(<span class=hljs-number >1</span>, -<span class=hljs-number >1</span>).expand(<span class=hljs-number >1</span>, vec.size()[<span class=hljs-number >1</span>])
    <span class=hljs-keyword >return</span> max_score + \
        torch.log(torch.<span class=hljs-built_in >sum</span>(torch.exp(vec - max_score_broadcast)))</code></pre> <p>create model </p> <pre><code class="python hljs"><span class=hljs-keyword >class</span> <span class="hljs-title class_">BiLSTM_CRF</span>(nn.Module):

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self, vocab_size, tag_to_ix, embedding_dim, hidden_dim</span>):
        <span class=hljs-built_in >super</span>(BiLSTM_CRF, <span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.embedding_dim = embedding_dim
        <span class="hljs-variable language_">self</span>.hidden_dim = hidden_dim
        <span class="hljs-variable language_">self</span>.vocab_size = vocab_size
        <span class="hljs-variable language_">self</span>.tag_to_ix = tag_to_ix
        <span class="hljs-variable language_">self</span>.tagset_size = <span class=hljs-built_in >len</span>(tag_to_ix)

        <span class="hljs-variable language_">self</span>.word_embeds = nn.Embedding(vocab_size, embedding_dim)
        <span class="hljs-variable language_">self</span>.lstm = nn.LSTM(embedding_dim, hidden_dim // <span class=hljs-number >2</span>,
                            num_layers=<span class=hljs-number >1</span>, bidirectional=<span class=hljs-literal >True</span>)

        <span class=hljs-comment ># Maps the output of the LSTM into tag space.</span>
        <span class="hljs-variable language_">self</span>.hidden2tag = nn.Linear(hidden_dim, <span class="hljs-variable language_">self</span>.tagset_size)

        <span class=hljs-comment ># Matrix of transition parameters.  Entry i,j is the score of</span>
        <span class=hljs-comment ># transitioning *to* i *from* j.</span>
        <span class="hljs-variable language_">self</span>.transitions = nn.Parameter(
            torch.randn(<span class="hljs-variable language_">self</span>.tagset_size, <span class="hljs-variable language_">self</span>.tagset_size))

        <span class=hljs-comment ># These two statements enforce the constraint that we never transfer</span>
        <span class=hljs-comment ># to the start tag and we never transfer from the stop tag</span>
        <span class="hljs-variable language_">self</span>.transitions.data[tag_to_ix[START_TAG], :] = -<span class=hljs-number >10000</span>
        <span class="hljs-variable language_">self</span>.transitions.data[:, tag_to_ix[STOP_TAG]] = -<span class=hljs-number >10000</span>

        <span class="hljs-variable language_">self</span>.hidden = <span class="hljs-variable language_">self</span>.init_hidden()

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">init_hidden</span>(<span class=hljs-params >self</span>):
        <span class=hljs-keyword >return</span> (torch.randn(<span class=hljs-number >2</span>, <span class=hljs-number >1</span>, <span class="hljs-variable language_">self</span>.hidden_dim // <span class=hljs-number >2</span>),
                torch.randn(<span class=hljs-number >2</span>, <span class=hljs-number >1</span>, <span class="hljs-variable language_">self</span>.hidden_dim // <span class=hljs-number >2</span>))

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">_forward_alg</span>(<span class=hljs-params >self, feats</span>):
        <span class=hljs-comment ># Do the forward algorithm to compute the partition function</span>
        init_alphas = torch.full((<span class=hljs-number >1</span>, <span class="hljs-variable language_">self</span>.tagset_size), -<span class=hljs-number >10000.</span>)
        <span class=hljs-comment ># START_TAG has all of the score.</span>
        init_alphas[<span class=hljs-number >0</span>][<span class="hljs-variable language_">self</span>.tag_to_ix[START_TAG]] = <span class=hljs-number >0.</span>

        <span class=hljs-comment ># Wrap in a variable so that we will get automatic backprop</span>
        forward_var = init_alphas

        <span class=hljs-comment ># Iterate through the sentence</span>
        <span class=hljs-keyword >for</span> feat <span class=hljs-keyword >in</span> feats:
            alphas_t = []  <span class=hljs-comment ># The forward tensors at this timestep</span>
            <span class=hljs-keyword >for</span> next_tag <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(<span class="hljs-variable language_">self</span>.tagset_size):
                <span class=hljs-comment ># broadcast the emission score: it is the same regardless of</span>
                <span class=hljs-comment ># the previous tag</span>
                emit_score = feat[next_tag].view(
                    <span class=hljs-number >1</span>, -<span class=hljs-number >1</span>).expand(<span class=hljs-number >1</span>, <span class="hljs-variable language_">self</span>.tagset_size)
                <span class=hljs-comment ># the ith entry of trans_score is the score of </span>
                <span class=hljs-comment ># transitioning to next_tag from i</span>
                trans_score = <span class="hljs-variable language_">self</span>.transitions[next_tag].view(<span class=hljs-number >1</span>, -<span class=hljs-number >1</span>)
                <span class=hljs-comment ># The ith entry of next_tag_var is the value for the</span>
                <span class=hljs-comment ># edge (i -&gt; next_tag) before we do log-sum-exp</span>
                next_tag_var = forward_var + trans_score + emit_score
                <span class=hljs-comment ># The forward variable for this tag is log-sum-exp of all the</span>
                <span class=hljs-comment ># scores.</span>
                alphas_t.append(log_sum_exp(next_tag_var).view(<span class=hljs-number >1</span>))
            forward_var = torch.cat(alphas_t).view(<span class=hljs-number >1</span>, -<span class=hljs-number >1</span>)
        terminal_var = forward_var + <span class="hljs-variable language_">self</span>.transitions[<span class="hljs-variable language_">self</span>.tag_to_ix[STOP_TAG]]
        alpha = log_sum_exp(terminal_var)
        <span class=hljs-keyword >return</span> alpha

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">_get_lstm_features</span>(<span class=hljs-params >self, sentence</span>):
        <span class="hljs-variable language_">self</span>.hidden = <span class="hljs-variable language_">self</span>.init_hidden()
        embeds = <span class="hljs-variable language_">self</span>.word_embeds(sentence).view(<span class=hljs-built_in >len</span>(sentence), <span class=hljs-number >1</span>, -<span class=hljs-number >1</span>)
        lstm_out, <span class="hljs-variable language_">self</span>.hidden = <span class="hljs-variable language_">self</span>.lstm(embeds, <span class="hljs-variable language_">self</span>.hidden)
        lstm_out = lstm_out.view(<span class=hljs-built_in >len</span>(sentence), <span class="hljs-variable language_">self</span>.hidden_dim)
        lstm_feats = <span class="hljs-variable language_">self</span>.hidden2tag(lstm_out)
        <span class=hljs-keyword >return</span> lstm_feats

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">_score_sentence</span>(<span class=hljs-params >self, feats, tags</span>):
        <span class=hljs-comment ># Gives the score of a provided tag sequence</span>
        score = torch.zeros(<span class=hljs-number >1</span>)
        tags = torch.cat([torch.tensor([<span class="hljs-variable language_">self</span>.tag_to_ix[START_TAG]], dtype=torch.long), tags])
        <span class=hljs-keyword >for</span> i, feat <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(feats):
            score = score + \
                <span class="hljs-variable language_">self</span>.transitions[tags[i + <span class=hljs-number >1</span>], tags[i]] + feat[tags[i + <span class=hljs-number >1</span>]]
        score = score + <span class="hljs-variable language_">self</span>.transitions[<span class="hljs-variable language_">self</span>.tag_to_ix[STOP_TAG], tags[-<span class=hljs-number >1</span>]]
        <span class=hljs-keyword >return</span> score

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">_viterbi_decode</span>(<span class=hljs-params >self, feats</span>):
        backpointers = []

        <span class=hljs-comment ># Initialize the viterbi variables in log space</span>
        init_vvars = torch.full((<span class=hljs-number >1</span>, <span class="hljs-variable language_">self</span>.tagset_size), -<span class=hljs-number >10000.</span>)
        init_vvars[<span class=hljs-number >0</span>][<span class="hljs-variable language_">self</span>.tag_to_ix[START_TAG]] = <span class=hljs-number >0</span>

        <span class=hljs-comment ># forward_var at step i holds the viterbi variables for step i-1</span>
        forward_var = init_vvars
        <span class=hljs-keyword >for</span> feat <span class=hljs-keyword >in</span> feats:
            bptrs_t = []  <span class=hljs-comment ># holds the backpointers for this step</span>
            viterbivars_t = []  <span class=hljs-comment ># holds the viterbi variables for this step</span>

            <span class=hljs-keyword >for</span> next_tag <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(<span class="hljs-variable language_">self</span>.tagset_size):
                <span class=hljs-comment ># next_tag_var[i] holds the viterbi variable for tag i at the</span>
                <span class=hljs-comment ># previous step, plus the score of transitioning</span>
                <span class=hljs-comment ># from tag i to next_tag.</span>
                <span class=hljs-comment ># We don&#x27;t include the emission scores here because the max</span>
                <span class=hljs-comment ># does not depend on them (we add them in below)</span>
                next_tag_var = forward_var + <span class="hljs-variable language_">self</span>.transitions[next_tag]
                best_tag_id = argmax(next_tag_var)
                bptrs_t.append(best_tag_id)
                viterbivars_t.append(next_tag_var[<span class=hljs-number >0</span>][best_tag_id].view(<span class=hljs-number >1</span>))
            <span class=hljs-comment ># Now add in the emission scores, and assign forward_var to the set</span>
            <span class=hljs-comment ># of viterbi variables we just computed</span>
            forward_var = (torch.cat(viterbivars_t) + feat).view(<span class=hljs-number >1</span>, -<span class=hljs-number >1</span>)
            backpointers.append(bptrs_t)

        <span class=hljs-comment ># Transition to STOP_TAG</span>
        terminal_var = forward_var + <span class="hljs-variable language_">self</span>.transitions[<span class="hljs-variable language_">self</span>.tag_to_ix[STOP_TAG]]
        best_tag_id = argmax(terminal_var)
        path_score = terminal_var[<span class=hljs-number >0</span>][best_tag_id]

        <span class=hljs-comment ># Follow the back pointers to decode the best path.</span>
        best_path = [best_tag_id]
        <span class=hljs-keyword >for</span> bptrs_t <span class=hljs-keyword >in</span> <span class=hljs-built_in >reversed</span>(backpointers):
            best_tag_id = bptrs_t[best_tag_id]
            best_path.append(best_tag_id)
        <span class=hljs-comment ># Pop off the start tag (we dont want to return that to the caller)</span>
        start = best_path.pop()
        <span class=hljs-keyword >assert</span> start == <span class="hljs-variable language_">self</span>.tag_to_ix[START_TAG]  <span class=hljs-comment ># Sanity check</span>
        best_path.reverse()
        <span class=hljs-keyword >return</span> path_score, best_path

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">neg_log_likelihood</span>(<span class=hljs-params >self, sentence, tags</span>):
        feats = <span class="hljs-variable language_">self</span>._get_lstm_features(sentence)
        forward_score = <span class="hljs-variable language_">self</span>._forward_alg(feats)
        gold_score = <span class="hljs-variable language_">self</span>._score_sentence(feats, tags)
        <span class=hljs-keyword >return</span> forward_score - gold_score

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, sentence</span>):  <span class=hljs-comment ># dont confuse this with _forward_alg above.</span>
        <span class=hljs-comment ># Get the emission scores from the BiLSTM</span>
        lstm_feats = <span class="hljs-variable language_">self</span>._get_lstm_features(sentence)

        <span class=hljs-comment ># Find the best path, given the features.</span>
        score, tag_seq = <span class="hljs-variable language_">self</span>._viterbi_decode(lstm_feats)
        <span class=hljs-keyword >return</span> score, tag_seq</code></pre> <p>run training </p> <pre><code class="python hljs">START_TAG = <span class=hljs-string >&quot;&lt;START&gt;&quot;</span>
STOP_TAG = <span class=hljs-string >&quot;&lt;STOP&gt;&quot;</span>
EMBEDDING_DIM = <span class=hljs-number >5</span>
HIDDEN_DIM = <span class=hljs-number >4</span>

<span class=hljs-comment ># Make up some training data</span>
training_data = [(
    <span class=hljs-string >&quot;the wall street journal reported today that apple corporation made money&quot;</span>.split(),
    <span class=hljs-string >&quot;B I I I O O O B I O O&quot;</span>.split()
), (
    <span class=hljs-string >&quot;georgia tech is a university in georgia&quot;</span>.split(),
    <span class=hljs-string >&quot;B I O O O O B&quot;</span>.split()
)]

word_to_ix = {}
<span class=hljs-keyword >for</span> sentence, tags <span class=hljs-keyword >in</span> training_data:
    <span class=hljs-keyword >for</span> word <span class=hljs-keyword >in</span> sentence:
        <span class=hljs-keyword >if</span> word <span class=hljs-keyword >not</span> <span class=hljs-keyword >in</span> word_to_ix:
            word_to_ix[word] = <span class=hljs-built_in >len</span>(word_to_ix)

tag_to_ix = {<span class=hljs-string >&quot;B&quot;</span>: <span class=hljs-number >0</span>, <span class=hljs-string >&quot;I&quot;</span>: <span class=hljs-number >1</span>, <span class=hljs-string >&quot;O&quot;</span>: <span class=hljs-number >2</span>, START_TAG: <span class=hljs-number >3</span>, STOP_TAG: <span class=hljs-number >4</span>}

model = BiLSTM_CRF(<span class=hljs-built_in >len</span>(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)
optimizer = optim.SGD(model.parameters(), lr=<span class=hljs-number >0.01</span>, weight_decay=<span class=hljs-number >1e-4</span>)

<span class=hljs-comment ># Check predictions before training</span>
<span class=hljs-keyword >with</span> torch.no_grad():
    precheck_sent = prepare_sequence(training_data[<span class=hljs-number >0</span>][<span class=hljs-number >0</span>], word_to_ix)
    precheck_tags = torch.tensor([tag_to_ix[t] <span class=hljs-keyword >for</span> t <span class=hljs-keyword >in</span> training_data[<span class=hljs-number >0</span>][<span class=hljs-number >1</span>]], dtype=torch.long)
    <span class=hljs-built_in >print</span>(model(precheck_sent))

<span class=hljs-comment ># Make sure prepare_sequence from earlier in the LSTM section is loaded</span>
<span class=hljs-keyword >for</span> epoch <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(
        <span class=hljs-number >300</span>):  <span class=hljs-comment ># again, normally you would NOT do 300 epochs, it is toy data</span>
    <span class=hljs-keyword >for</span> sentence, tags <span class=hljs-keyword >in</span> training_data:
        <span class=hljs-comment ># Step 1. Remember that Pytorch accumulates gradients.</span>
        <span class=hljs-comment ># We need to clear them out before each instance</span>
        model.zero_grad()

        <span class=hljs-comment ># Step 2. Get our inputs ready for the network, that is,</span>
        <span class=hljs-comment ># turn them into Tensors of word indices.</span>
        sentence_in = prepare_sequence(sentence, word_to_ix)
        targets = torch.tensor([tag_to_ix[t] <span class=hljs-keyword >for</span> t <span class=hljs-keyword >in</span> tags], dtype=torch.long)

        <span class=hljs-comment ># Step 3. Run our forward pass.</span>
        loss = model.neg_log_likelihood(sentence_in, targets)

        <span class=hljs-comment ># Step 4. Compute the loss, gradients, and update the parameters by</span>
        <span class=hljs-comment ># calling optimizer.step()</span>
        loss.backward()
        optimizer.step()

<span class=hljs-comment ># Check predictions after training</span>
<span class=hljs-keyword >with</span> torch.no_grad():
    precheck_sent = prepare_sequence(training_data[<span class=hljs-number >0</span>][<span class=hljs-number >0</span>], word_to_ix)
    <span class=hljs-built_in >print</span>(model(precheck_sent))
<span class=hljs-comment ># We got it!</span></code></pre> <div class=page-foot > <div class=copyright > <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a> ©️ Last modified: December 04, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/nlpwme/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>