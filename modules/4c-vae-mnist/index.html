<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/nlpwme/libs/katex/katex.min.css"> <link rel=stylesheet  href="/nlpwme/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/nlpwme/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/nlpwme/css/font-awesome.min.css"> <link rel=stylesheet  href="/nlpwme/css/celeste.min.css"> <link rel=icon  type="image/png" sizes=200x200  href="/nlpwme/assets/robot.png"> <link rel=icon  type="image/png" sizes=152x152  href="/nlpwme/assets/robot_smaller_152x152.png"> <link rel=icon  type="image/x-icon" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/x-icon" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <link rel=icon  type="image/png" sizes=64x64  href="/nlpwme/assets/robot_smaller_64x64.png"> <link rel=icon  type="image/png" sizes=32x32  href="/nlpwme/assets/robot_smaller_32x32.png"> <title>NLPwShiyi | Natural Language Processing with Shiyi</title> <nav id=navbar  class=navigation  role=navigation > <input id=toggle1  type=checkbox  /> <label class=hamburger1  for=toggle1 > <div class=top ></div> <div class=meat ></div> <div class=bottom ></div> </label> <nav class="topnav mx-auto" id=myTopnav > <div class=dropdown > <button class=dropbtn >Comp Ling <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/1b-info-theory">Information Theory</a> <a href="/nlpwme/modules/1c-noisy-channel-model">The Noisy Channel Model</a> <a href="/nlpwme/modules/1d-finite-automata">FSAs and FSTs</a> <a href="/nlpwme/modules/1e-mutual-info">Mutual Information</a> <a href="/nlpwme/modules/1f-cky-algorithm">CKY Algorithm</a> <a href="/nlpwme/modules/1g-viterbi">Viterbi Algorithm</a> <a href="/nlpwme/modules/2b-markov-processes">Markov Processes</a> <a href="/nlpwme/modules/1h-semantics">Logic and Problem Solving</a> <a href="/nlpwme/modules/1j-bayesian">Bayesian Inference</a> </div> </div> <div class=dropdown > <button class=dropbtn  >ML / DL <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/2e-jax">Jacobian Matrices Derivation</a> <a href="/nlpwme/modules/2d-automatic-differentiation">Automatic Differentiation</a> <a href="/nlpwme/modules/2f-loss-functions">Stochastic GD</a> <a href="/nlpwme/modules/2c-word2vec">Word2Vec</a> <a href="/nlpwme/modules/2g-batchnorm">Batchnorm</a> <a href="/nlpwme/modules/2j-perplexity">Perplexity</a> <a href="/nlpwme/modules/2h-dropout">Dropout</a> <a href="/nlpwme/modules/2i-depth">Depth: Pros and Cons</a> <a href="/nlpwme/modules/2k-VAE">Variational Autoencoders</a> <a href="/nlpwme/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a> </div> </div> <a href="/nlpwme/" class=active >Intro </a> <div class=dropdown > <button class=dropbtn  >SOTA <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a> <a href="/nlpwme/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a> <a href="/nlpwme/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a> <a href="/nlpwme/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a> <a href="/nlpwme/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a> </div> </div> <div class=dropdown > <button class=dropbtn  >Hands-on <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/4a-mlp-from-scratch">MLP from Scratch</a> <a href="/nlpwme/modules/4b-generative-adversarial-networks">GAN Example </a> <a href="/nlpwme/modules/4c-vae-mnist">VAE for MNIST</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">BI-LSTM-CRF Seq2Seq</a> <a href="/nlpwme/modules/4e-c4fe-tbip">Measuring Subjectivity with VAE</a> <a href="/nlpwme/modules/4g-etl-job">Serverless ETL Example</a> <a href="/nlpwme/modules/4h-ocr-data-aug">OCR Text Augmentation</a> <a href="/nlpwme/modules/4i-neo4j-gql">Neo4j GQL Example</a> </div> </div> </nav> </nav> <script src="../assets/js/custom.js"></script> <div class=franklin-content ><h2 id=vae_for_mnist_image_classification ><a href="#vae_for_mnist_image_classification" class=header-anchor >VAE for MNIST Image Classification</a></h2> <div class=franklin-toc ><ol><li><a href="#vae_for_mnist_image_classification">VAE for MNIST Image Classification</a><li><a href="#breakdown_of_the_math">Breakdown of the Math</a><li><a href="#cheating_with_the_conditional_vae">Cheating with the &#39;conditional&#39; VAE</a></ol></div> <p>In this section, we are going to go through some practical code examples of variational encoding method for MNIST image classification.</p> <pre><code class="python hljs"><span class=hljs-keyword >import</span> os
<span class=hljs-keyword >import</span> torch
<span class=hljs-keyword >import</span> torch.nn <span class=hljs-keyword >as</span> nn
<span class=hljs-keyword >import</span> torch.nn.functional <span class=hljs-keyword >as</span> F
<span class=hljs-keyword >import</span> torchvision
<span class=hljs-keyword >from</span> torchvision <span class=hljs-keyword >import</span> transforms
<span class=hljs-keyword >from</span> torchvision.utils <span class=hljs-keyword >import</span> save_image

<span class=hljs-keyword >import</span> numpy <span class=hljs-keyword >as</span> np
<span class=hljs-keyword >import</span> matplotlib.pyplot <span class=hljs-keyword >as</span> plt
%matplotlib inline

<span class=hljs-keyword >from</span> sklearn.metrics.cluster <span class=hljs-keyword >import</span> normalized_mutual_info_score

<span class=hljs-keyword >def</span> <span class="hljs-title function_">show</span>(<span class=hljs-params >img</span>):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (<span class=hljs-number >1</span>,<span class=hljs-number >2</span>,<span class=hljs-number >0</span>)), interpolation=<span class=hljs-string >&#x27;nearest&#x27;</span>)
    
<span class=hljs-keyword >def</span> <span class="hljs-title function_">plot_reconstruction</span>(<span class=hljs-params >model, n=<span class=hljs-number >24</span></span>):
    x,_ = <span class=hljs-built_in >next</span>(<span class=hljs-built_in >iter</span>(data_loader))
    x = x[:n,:,:,:].to(device)
    <span class=hljs-keyword >try</span>:
        out, _, _, log_p = model(x.view(-<span class=hljs-number >1</span>, image_size)) 
    <span class=hljs-keyword >except</span>:
        out, _, _ = model(x.view(-<span class=hljs-number >1</span>, image_size)) 
    x_concat = torch.cat([x.view(-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, <span class=hljs-number >28</span>, <span class=hljs-number >28</span>), out.view(-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, <span class=hljs-number >28</span>, <span class=hljs-number >28</span>)], dim=<span class=hljs-number >3</span>)
    out_grid = torchvision.utils.make_grid(x_concat).cpu().data
    show(out_grid)

<span class=hljs-keyword >def</span> <span class="hljs-title function_">plot_generation</span>(<span class=hljs-params >model, n=<span class=hljs-number >24</span></span>):
    <span class=hljs-keyword >with</span> torch.no_grad():
        z = torch.randn(n, z_dim).to(device)
        out = model.decode(z).view(-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, <span class=hljs-number >28</span>, <span class=hljs-number >28</span>)

    out_grid = torchvision.utils.make_grid(out).cpu()
    show(out_grid)

<span class=hljs-keyword >def</span> <span class="hljs-title function_">plot_conditional_generation</span>(<span class=hljs-params >model, n=<span class=hljs-number >8</span>, fix_number=<span class=hljs-literal >None</span></span>):
    <span class=hljs-keyword >with</span> torch.no_grad():
        matrix = np.zeros((n,n_classes))
        matrix[:,<span class=hljs-number >0</span>] = <span class=hljs-number >1</span>

        <span class=hljs-keyword >if</span> fix_number <span class=hljs-keyword >is</span> <span class=hljs-literal >None</span>:
            final = matrix[:]
            <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(<span class=hljs-number >1</span>,n_classes):
                final = np.vstack((final,np.roll(matrix,i)))
            <span class=hljs-comment >#z = torch.randn(8*n_classes, z_dim).to(device)</span>
            z = torch.randn(<span class=hljs-number >8</span>, z_dim)
            z = z.repeat(n_classes,<span class=hljs-number >1</span>).to(device)
            y_onehot = torch.tensor(final).<span class=hljs-built_in >type</span>(torch.FloatTensor).to(device)
            out = model.decode(z,y_onehot).view(-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, <span class=hljs-number >28</span>, <span class=hljs-number >28</span>)
        <span class=hljs-keyword >else</span>:
            z = torch.randn(n, z_dim).to(device)
            y_onehot = torch.tensor(np.roll(matrix, fix_number))
                       .<span class=hljs-built_in >type</span>(torch.FloatTensor).to(device)
            out = model.decode(z,y_onehot).view(-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>, <span class=hljs-number >28</span>, <span class=hljs-number >28</span>)

    out_grid = torchvision.utils.make_grid(out).cpu()
    show(out_grid)</code></pre> <pre><code class="python hljs"><span class=hljs-comment ># Device configuration</span>
device = torch.device(<span class=hljs-string >&#x27;cuda&#x27;</span> <span class=hljs-keyword >if</span> torch.cuda.is_available() <span class=hljs-keyword >else</span> <span class=hljs-string >&#x27;cpu&#x27;</span>)

<span class=hljs-comment ># Create a directory if not exists</span>
sample_dir = <span class=hljs-string >&#x27;samples&#x27;</span>
<span class=hljs-keyword >if</span> <span class=hljs-keyword >not</span> os.path.exists(sample_dir):
    os.makedirs(sample_dir)</code></pre> <pre><code class="python hljs">data_dir = <span class=hljs-string >&#x27;data&#x27;</span>
<span class=hljs-comment ># MNIST dataset</span>
dataset = torchvision.datasets.MNIST(root=data_dir,
                                     train=<span class=hljs-literal >True</span>,
                                     transform=transforms.ToTensor(),
                                     download=<span class=hljs-literal >True</span>)

<span class=hljs-comment ># Data loader</span>
data_loader = torch.utils.data.DataLoader(dataset=dataset,
                                          batch_size=<span class=hljs-number >128</span>, 
                                          shuffle=<span class=hljs-literal >True</span>)

test_loader = torch.utils.data.DataLoader(
    torchvision.datasets.MNIST(data_dir, train=<span class=hljs-literal >False</span>, download=<span class=hljs-literal >True</span>, transform=transforms.ToTensor()),
    batch_size=<span class=hljs-number >10</span>, shuffle=<span class=hljs-literal >False</span>)</code></pre> <h2 id=breakdown_of_the_math ><a href="#breakdown_of_the_math" class=header-anchor >Breakdown of the Math</a></h2> <p>Consider a latent variable model with a data variable <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mi mathvariant=script >X</mi></mrow><annotation encoding="application/x-tex">x\in \mathcal{X}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span> and a latent variable <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>∈</mo><mi mathvariant=script >Z</mi></mrow><annotation encoding="application/x-tex">z\in \mathcal{Z}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.07944em;">Z</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo separator=true >,</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(z,x) = p(z)p_\theta(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>. Given the data <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator=true >,</mo><mo>…</mo><mo separator=true >,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1,\dots, x_n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner >…</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we want to train the model by maximizing the marginal log-likelihood:</p> <div class=nonumber ><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.16em  columnalign="right center left" columnspacing=1em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=false ><mrow><mi mathvariant=script >L</mi><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mo>∫</mo><mi mathvariant=script >Z</mi></msub><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mi>d</mi><mi>z</mi><mo fence=true >]</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{rcl} \mathcal{L} = \mathbf{E}_{p_d(x)}\left[\log p_\theta(x)\right]=\mathbf{E}_{p_d(x)}\left[\log \int_{\mathcal{Z}}p_{\theta}(x|z)p(z)dz\right] \end{array}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.21em;vertical-align:-0.355em;"></span><span class=mord ><span class=mtable ><span class=arraycolsep  style="width:0.5em;"></span><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.855em;"><span style="top:-3.005em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathcal">L</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop ><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0006em;">∫</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1225em;"><span style="top:-2.3442em;margin-left:-0.1945em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.07944em;">Z</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3558em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.355em;"><span></span></span></span></span></span><span class=arraycolsep  style="width:0.5em;"></span></span></span></span></span></span></span></div> <p>where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">p_d</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> denotes the empirical distribution of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>δ</mi><msub><mi>x</mi><mi>i</mi></msub></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_d(x) =\frac{1}{n}\sum_{i=1}^n \delta_{x_i}(x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1.1901em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8451em;"><span style="top:-2.655em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2997em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2501em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span>.</p> <p>To avoid the &#40;often&#41; difficult computation of the integral above, the idea behind variational methods is to instead maximize a lower bound to the log-likelihood:</p> <div class=nonumber ><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.16em  columnalign="right center left" columnspacing=1em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=false ><mrow><mi mathvariant=script >L</mi><mo>≥</mo><mi>L</mi><mo stretchy=false >(</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo separator=true >,</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mo stretchy=false >)</mo><mo>=</mo><msub><mi mathvariant=bold >E</mi><mrow><msub><mi>p</mi><mi>d</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><msub><mi mathvariant=bold >E</mi><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow><mo>−</mo><mrow><mi mathvariant=normal >K</mi><mi mathvariant=normal >L</mi></mrow><mrow><mo fence=true >(</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >)</mo></mrow><mo fence=true >]</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{rcl} \mathcal{L} \geq L(p_\theta(x|z),q(z|x)) =\mathbf{E}_{p_d(x)}\left[\mathbf{E}_{q(z|x)}\left[\log p_\theta(x|z)\right]-\mathrm{KL}\left( q(z|x)||p(z)\right)\right] \end{array}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.21em;vertical-align:-0.355em;"></span><span class=mord ><span class=mtable ><span class=arraycolsep  style="width:0.5em;"></span><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.855em;"><span style="top:-3.005em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathcal">L</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >≥</span><span class=mspace  style="margin-right:0.2778em;"></span><span class="mord mathnormal">L</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >))</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mord ><span class="mord mathrm">KL</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mord >∣∣</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.355em;"><span></span></span></span></span></span><span class=arraycolsep  style="width:0.5em;"></span></span></span></span></span></span></span></div> <p>Any choice of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> gives a valid lower bound. Variational autoencoders replace the variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> by an inference network <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_{\phi}(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> that is trained together with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span> to jointly maximize <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy=false >(</mo><msub><mi>p</mi><mi>θ</mi></msub><mo separator=true >,</mo><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">L(p_\theta,q_\phi)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">L</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span></p> <p>The variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_{\phi}(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> is also called the <strong>encoder</strong> and the generative model <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>, the <strong>decoder</strong> or generator.</p> <p>The first term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant=bold >E</mi><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{E}_{q(z|x)}\left[\log p_\theta(x|z)\right]</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.1052em;vertical-align:-0.3552em;"></span><span class=mord ><span class="mord mathbf">E</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3552em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span> is the negative reconstruction error. Indeed under a gaussian assumption i.e. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo><mo>=</mo><mi mathvariant=script >N</mi><mo stretchy=false >(</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo separator=true >,</mo><mi>I</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x|z) = \mathcal{N}(\mu_{\theta}(z), I)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">μ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mclose >)</span></span></span></span> the term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mi mathvariant=normal >∣</mi><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\log p_\theta(x|z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span> reduces to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∝</mo><mi mathvariant=normal >∥</mi><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><msup><mi mathvariant=normal >∥</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\propto \|x-\mu_\theta(z)\|^2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.4306em;"></span><span class=mrel >∝</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >∥</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1.0641em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">μ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mord ><span class=mord >∥</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>, which is often used in practice. The term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant=normal >K</mi><mi mathvariant=normal >L</mi></mrow><mrow><mo fence=true >(</mo><mi>q</mi><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{KL}\left( q(z|x)||p(z)\right)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathrm">KL</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mord >∣∣</span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> can be seen as a regularization term, where the variational posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy=false >(</mo><mi>z</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q_\phi(z|x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0361em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mord >∣</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> should be matched to the prior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo><mo>=</mo><mi mathvariant=script >N</mi><mo stretchy=false >(</mo><mn>0</mn><mo separator=true >,</mo><mi>I</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(z)= \mathcal{N}(0, I)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class=mopen >(</span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mclose >)</span></span></span></span>.</p> <p>Variational Autoencoders were introduced by <a href="https://arxiv.org/abs/1312.6114">Kingma and Welling &#40;2013&#41;</a>, see also <a href="https://arxiv.org/abs/1606.05908">&#40;Doersch, 2016&#41;</a> for a tutorial.</p> <p>There are various examples of VAE in PyTorch available <a href="https://github.com/pytorch/examples/tree/master/vae">here</a> or <a href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65">here</a>. The code below is taken from this last source.</p> <hr /> <p><img src="../extras/dnns/vae.png" alt=vae  /></p> <hr /> <pre><code class="python hljs"><span class=hljs-comment ># Hyper-parameters</span>
image_size = <span class=hljs-number >784</span>
h_dim = <span class=hljs-number >400</span>
z_dim = <span class=hljs-number >20</span>
num_epochs = <span class=hljs-number >15</span>
learning_rate = <span class=hljs-number >1e-3</span>

<span class=hljs-comment ># VAE model</span>
<span class=hljs-keyword >class</span> <span class="hljs-title class_">VAE</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self, image_size=<span class=hljs-number >784</span>, h_dim=<span class=hljs-number >400</span>, z_dim=<span class=hljs-number >20</span></span>):
        <span class=hljs-built_in >super</span>(VAE, <span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(image_size, h_dim)
        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(h_dim, z_dim)
        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(h_dim, z_dim)
        <span class="hljs-variable language_">self</span>.fc4 = nn.Linear(z_dim, h_dim)
        <span class="hljs-variable language_">self</span>.fc5 = nn.Linear(h_dim, image_size)
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">encode</span>(<span class=hljs-params >self, x</span>):
        h = F.relu(<span class="hljs-variable language_">self</span>.fc1(x))
        <span class=hljs-keyword >return</span> <span class="hljs-variable language_">self</span>.fc2(h), <span class="hljs-variable language_">self</span>.fc3(h)
    
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">reparameterize</span>(<span class=hljs-params >self, mu, log_var</span>):
        std = torch.exp(log_var/<span class=hljs-number >2</span>)
        eps = torch.randn_like(std)
        <span class=hljs-keyword >return</span> mu + eps * std

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">decode</span>(<span class=hljs-params >self, z</span>):
        h = F.relu(<span class="hljs-variable language_">self</span>.fc4(z))
        <span class=hljs-keyword >return</span> torch.sigmoid(<span class="hljs-variable language_">self</span>.fc5(h))
    
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, x</span>):
        mu, log_var = <span class="hljs-variable language_">self</span>.encode(x)
        z = <span class="hljs-variable language_">self</span>.reparameterize(mu, log_var)
        x_reconst = <span class="hljs-variable language_">self</span>.decode(z)
        <span class=hljs-keyword >return</span> x_reconst, mu, log_var

model = VAE().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</code></pre> <p>Here for the loss, instead of MSE for the reconstruction loss, we take Binary Cross-Entropy. The code below is still from the PyTorch tutorial &#40;with minor modifications to avoid warnings&#33;&#41;.</p> <pre><code class="python hljs"><span class=hljs-comment ># Start training</span>
<span class=hljs-keyword >for</span> epoch <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(num_epochs):
    <span class=hljs-keyword >for</span> i, (x, _) <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(data_loader):
        <span class=hljs-comment ># Forward pass</span>
        x = x.to(device).view(-<span class=hljs-number >1</span>, image_size)
        x_reconst, mu, log_var = model(x)
        
        <span class=hljs-comment ># Compute reconstruction loss and kl divergence</span>
        <span class=hljs-comment ># For KL divergence between Gaussians, see Appendix B in VAE paper or (Doersch, 2016):</span>
        <span class=hljs-comment ># https://arxiv.org/abs/1606.05908</span>
        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction=<span class=hljs-string >&#x27;sum&#x27;</span>)
        kl_div = - <span class=hljs-number >0.5</span> * torch.<span class=hljs-built_in >sum</span>(<span class=hljs-number >1</span> + log_var - mu.<span class=hljs-built_in >pow</span>(<span class=hljs-number >2</span>) - log_var.exp())
        
        <span class=hljs-comment ># Backprop and optimize</span>
        loss = reconst_loss + kl_div
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        <span class=hljs-keyword >if</span> (i+<span class=hljs-number >1</span>) % <span class=hljs-number >10</span> == <span class=hljs-number >0</span>:
            <span class=hljs-built_in >print</span> (<span class=hljs-string >&quot;Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}&quot;</span> 
                   .<span class=hljs-built_in >format</span>(epoch+<span class=hljs-number >1</span>, num_epochs, i+<span class=hljs-number >1</span>, <span class=hljs-built_in >len</span>(data_loader), reconst_loss.item()/<span class=hljs-built_in >len</span>(x), kl_div.item()/<span class=hljs-built_in >len</span>(x)))</code></pre> <p>Let see how our network reconstructs our last batch. We display pairs of original digits and reconstructed version.</p> <pre><code class="python hljs">plot_reconstruction(model)</code></pre>
<p>Let&#39;s see now how our network generates new samples.</p>
<pre><code class="python hljs">plot_generation(model)</code></pre>
<p>Not great, but we did not train our network for long... That being said, we have no control of the generated digits. In the rest of this notebook, we explore ways to generates zeroes, ones, twos and so on.</p>
<p>As a by-product, we show how our VAE will allow us to do clustering thanks to the Gumbel VAE described below. But before that, we start by cheating a little bit...</p>
<h2 id=cheating_with_the_conditional_vae ><a href="#cheating_with_the_conditional_vae" class=header-anchor >Cheating with the &#39;conditional&#39; VAE</a></h2>
<p>We will first use the labels here &#40;like what we did in the course with Conditional GAN&#41;. The idea is to modify slightly the architecture above by feeding a one hot version of the label to the decoder in addition to the code computed by the decoder.</p>
<p>First code a function transforming a label in its one hot encoding. This function will be used in the training loop &#40;not in the architecture of the neural network&#33;&#41;.</p>
<pre><code class="python hljs">n_classes = <span class=hljs-number >10</span>
<span class=hljs-keyword >def</span> <span class="hljs-title function_">l_2_onehot</span>(<span class=hljs-params >labels,nb_digits=n_classes</span>):
    <span class=hljs-comment ># take labels (from the dataloader) and return labels onehot-encoded</span>
    <span class=hljs-comment >#</span>
    <span class=hljs-comment ># your code here</span>
    <span class=hljs-comment >#</span></code></pre>
<p>You can test it on a batch.</p>
<pre><code class="python hljs">(x,labels) = <span class=hljs-built_in >next</span>(<span class=hljs-built_in >iter</span>(data_loader))</code></pre>
<p>Now modify the architecture of the VAE where the decoder takes as input the random code concatenated with the onehot encoding of the label.</p>
<pre><code class="python hljs">n_classes = <span class=hljs-number >10</span>

<span class=hljs-keyword >class</span> <span class="hljs-title class_">VAE_Cond</span>(nn.Module):
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">__init__</span>(<span class=hljs-params >self, image_size=<span class=hljs-number >784</span>, h_dim=<span class=hljs-number >400</span>, z_dim=<span class=hljs-number >20</span>, n_classes = <span class=hljs-number >10</span></span>):
        <span class=hljs-built_in >super</span>(VAE_Cond, <span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(image_size, h_dim)
        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(h_dim, z_dim)
        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(h_dim, z_dim)
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here</span>
        <span class=hljs-comment >#</span>
        
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">encode</span>(<span class=hljs-params >self, x</span>):
        h = F.relu(<span class="hljs-variable language_">self</span>.fc1(x))
        <span class=hljs-keyword >return</span> <span class="hljs-variable language_">self</span>.fc2(h), <span class="hljs-variable language_">self</span>.fc3(h)
    
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">reparameterize</span>(<span class=hljs-params >self, mu, log_var</span>):
        std = torch.exp(log_var/<span class=hljs-number >2</span>)
        eps = torch.randn_like(std)
        <span class=hljs-keyword >return</span> mu + eps * std

    <span class=hljs-keyword >def</span> <span class="hljs-title function_">decode</span>(<span class=hljs-params >self, z, l_onehot</span>):
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here / use torch.cat </span>
        <span class=hljs-comment >#      </span>
    
    <span class=hljs-keyword >def</span> <span class="hljs-title function_">forward</span>(<span class=hljs-params >self, x, l_onehot</span>):
        <span class=hljs-comment >#</span>
        <span class=hljs-comment ># your code here / use F.gumbel_softmax</span>
        <span class=hljs-comment >#</span></code></pre>
<p>Test your new model on a batch:</p>
<pre><code class="python hljs">model_C = VAE_Cond().to(device)
x = x.to(device).view(-<span class=hljs-number >1</span>, image_size)
l_onehot = l_2_onehot(labels)
l_onehot = l_onehot.to(device)
model_C(x, l_onehot)</code></pre>
<p>Now you can modify the training loop of your network. The parameter   will allow you to scale the KL term in your loss as explained in the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> -VAE paper see formula &#40;4&#41; in the paper.</p>
<pre><code class="python hljs"><span class=hljs-keyword >def</span> <span class="hljs-title function_">train_C</span>(<span class=hljs-params >model, data_loader=data_loader,num_epochs=num_epochs, beta=<span class=hljs-number >10.</span>, verbose=<span class=hljs-literal >True</span></span>):
    nmi_scores = []
    model.train(<span class=hljs-literal >True</span>)
    <span class=hljs-keyword >for</span> epoch <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(num_epochs):
        <span class=hljs-keyword >for</span> i, (x, labels) <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(data_loader):
            <span class=hljs-comment ># Forward pass</span>
            x = x.to(device).view(-<span class=hljs-number >1</span>, image_size)
            <span class=hljs-comment >#</span>
            <span class=hljs-comment ># your code here</span>
            <span class=hljs-comment >#</span>
            
            
            reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction=<span class=hljs-string >&#x27;sum&#x27;</span>)
            kl_div =  - <span class=hljs-number >0.5</span> * torch.<span class=hljs-built_in >sum</span>(<span class=hljs-number >1</span> + log_var - mu.<span class=hljs-built_in >pow</span>(<span class=hljs-number >2</span>) - log_var.exp())
            
            <span class=hljs-comment ># Backprop and optimize</span>
            loss = reconst_loss + beta*kl_div
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            <span class=hljs-keyword >if</span> verbose:
                <span class=hljs-keyword >if</span> (i+<span class=hljs-number >1</span>) % <span class=hljs-number >10</span> == <span class=hljs-number >0</span>:
                    <span class=hljs-built_in >print</span>(<span class=hljs-string >&quot;Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}&quot;</span>
                           .<span class=hljs-built_in >format</span>(epoch+<span class=hljs-number >1</span>, num_epochs, i+<span class=hljs-number >1</span>, <span class=hljs-built_in >len</span>(data_loader), reconst_loss.item()/<span class=hljs-built_in >len</span>(x),
                                   kl_div.item()/<span class=hljs-built_in >len</span>(x)))</code></pre>
<pre><code class="python hljs">model_C = VAE_Cond().to(device)
optimizer = torch.optim.Adam(model_C.parameters(), lr=learning_rate)</code></pre>
<pre><code class="python hljs">train_C(model_C,num_epochs=<span class=hljs-number >15</span>,verbose=<span class=hljs-literal >True</span>)

plot_conditional_generation(model_C, n=<span class=hljs-number >8</span>)</code></pre>
<p>Here you should get nice results. Now we will avoid the use of the labels...</p>
<div class=page-foot >
    <div class=copyright >
      <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a>
       ©️ Last modified: December 04, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
    </div>
  </div>
  </div>
    
        



    
    
        <script src="/nlpwme/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>